{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import glob\n",
    "from pyvis.network import Network\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference list of papers:  136837 136837\n",
      "number of excel sheets:  7093\n"
     ]
    }
   ],
   "source": [
    "PATH = [] # ALL excel sheets of different models to be found here\n",
    "MODEL = [] # ALL types of models in this analysis and visualization\n",
    "PATH.append(\"/Users/t/Desktop/CitationSpace/GoogleNet/\") # papers on GoogleNet's excel sheets are stored under this folder\n",
    "MODEL.append(\"GoogleNet\")\n",
    "PATH.append(\"/Users/t/Desktop/CitationSpace/ResNet/\") # papers on ResNet's excel sheets are stored under this folder\n",
    "MODEL.append(\"ResNet\")\n",
    "PATH.append(\"/Users/t/Desktop/CitationSpace/VGG/\") # papers on VGG's excel sheets are stored under this folder\n",
    "MODEL.append(\"VGG\")\n",
    "PATH.append(\"/Users/t/Desktop/CitationSpace/AlexNet/\") # papers on AlexNet's excel sheets are stored under this folder\n",
    "MODEL.append(\"AlexNet\")\n",
    "PATH.append(\"/Users/t/Desktop/CitationSpace/LeNet/\") # papers on LeNet's excel sheets are stored under this folder\n",
    "MODEL.append(\"LeNet\")\n",
    "PATH.append(\"/Users/t/Desktop/CitationSpace/SeNet/\") # papers on SeNet's excel sheets are stored under this folder\n",
    "MODEL.append(\"SeNet\")\n",
    "source = [] # sotre source article name\n",
    "target = [] # store target article name\n",
    "model_group = [] # store the source paper's model group\n",
    "count = 0 # to count the number of files existed in the folder\n",
    "for model in range(len(PATH)):\n",
    "    directory_len = len(PATH[model])\n",
    "    filenames = glob.glob(PATH[model] + \"*.xls\")\n",
    "    for file in filenames:\n",
    "        count = count + 1\n",
    "        # Crawl individual paper's reference list into \"source\" and \"target\" arrays\n",
    "        if file[-8:] == \"_ref.xls\":\n",
    "            # read all excel references list files\n",
    "            df = pd.read_excel(file)\n",
    "            # get reference list's column: the name of articles\n",
    "            Ref = df[\"Article Title\"]\n",
    "            new_target = 0\n",
    "            for paper in Ref:\n",
    "                target.append(paper)\n",
    "                new_target = new_target + 1\n",
    "            file_papername = file[directory_len : -8]\n",
    "            for i in range(new_target):\n",
    "                source.append(file_papername)\n",
    "                model_group.append(MODEL[model])\n",
    "        elif file[-9:] == \"_cite.xls\":\n",
    "            # read all excel citations list files\n",
    "            dc = pd.read_excel(file)\n",
    "            # get citation list's column: the name of articles\n",
    "            Cite = dc[\"Article Title\"]\n",
    "            new_target = 0\n",
    "            for paper in Cite:\n",
    "                source.append(paper)\n",
    "                new_target = new_target + 1\n",
    "            file_papername = file[directory_len : -9]\n",
    "            for i in range(new_target):\n",
    "                target.append(file_papername)\n",
    "                model_group.append(MODEL[model])\n",
    "print(\"Reference list of papers: \", len(source), len(target))\n",
    "print(\"number of excel sheets: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Entries in Current Citation Space:  12680 12680 12680\n"
     ]
    }
   ],
   "source": [
    "Source0 = []\n",
    "Target0 = []\n",
    "Model_group0 = []\n",
    "len_limit = len(source)\n",
    "for i in range(len_limit):\n",
    "    if source[i] in target and target[i] in source:\n",
    "        Source0.append(source[i])\n",
    "        Target0.append(target[i])\n",
    "        Model_group0.append(model_group[i])\n",
    "print(\"Number of Entries in Current Citation Space: \", len(Source0), len(Target0), len(Model_group0))\n",
    "# erase arrays no longer using\n",
    "# source = []\n",
    "# target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Entries in Current Citation Space:  11698 11698 11698\n"
     ]
    }
   ],
   "source": [
    "result = sorted(zip(Source0, Target0, Model_group0))\n",
    "len_limit = len(result)\n",
    "num_repeat = 0\n",
    "for i in range(len_limit - 1):\n",
    "    if result[len_limit - 1 - i] == result[len_limit - 2 - i]:\n",
    "        # Delete those citation entries that are alike\n",
    "        result.pop(len_limit - 1 - i)\n",
    "        num_repeat = num_repeat + 1\n",
    "Source = []\n",
    "Target = []\n",
    "Model_group = []\n",
    "for i in range(len_limit - num_repeat):\n",
    "    Source.append(result[i][0])\n",
    "    Target.append(result[i][1])\n",
    "    Model_group.append(result[i][2])\n",
    "print(\"Number of Entries in Current Citation Space: \", len(Source), len(Target), len(Model_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total papers:  4834 4834 4834\n"
     ]
    }
   ],
   "source": [
    "paper = [] # Store article names\n",
    "paper_model = [] # Store article's filed of corresponding model\n",
    "count = [] # Store individual article's popularity (occurrence in this data base)\n",
    "len_limit = len(Source)\n",
    "for i in range(len_limit):\n",
    "    if Source[i] not in paper:\n",
    "        paper.append(Source[i])\n",
    "        paper_model.append(Model_group[i])\n",
    "        # to count the number of occurrences of a paper's title in both Source and Target\n",
    "        count_paper = 0\n",
    "        for j in range(len_limit):\n",
    "            if Target[j] == Source[i]:\n",
    "                count_paper = count_paper + 1\n",
    "        count.append(count_paper)\n",
    "    if Target[i] not in paper:\n",
    "        paper.append(Target[i])\n",
    "        paper_model.append(Model_group[i])\n",
    "        # to count the number of occurrences of a paper's title in both Source and Target\n",
    "        count_paper = 0\n",
    "        for j in range(len_limit):\n",
    "            if Target[j] == Target[i]:\n",
    "                count_paper = count_paper + 1\n",
    "        count.append(count_paper)\n",
    "print(\"number of total papers: \", len(paper), len(count), len(paper_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Entries in Current Citation Space:  11698\n",
      "Statistics about Edges' Weights\n",
      "Weight mean:  82.82552573089417\n",
      "Weight median:  17.0\n",
      "Weight standard deviation:  138.7333871793083\n"
     ]
    }
   ],
   "source": [
    "len_limit = len(paper)\n",
    "Weight = [] # to store the edge weight of all source and target article\n",
    "for i in range(len(Source)):\n",
    "    count_source = -1\n",
    "    count_target = -1\n",
    "    for j in range(len_limit):\n",
    "        if Source[i] == paper[j]:\n",
    "            count_source = count[j]\n",
    "        if Target[i] == paper[j]:\n",
    "            count_target = count[j]\n",
    "    if count_source != -1 and count_target != -1:\n",
    "        Weight.append(count_source + count_target)\n",
    "    else: # print out the missing article names if any\n",
    "        print(count_source, count_target)\n",
    "        print(Source[i])\n",
    "        print(Target[i])\n",
    "print(\"Number of Entries in Current Citation Space: \", len(Weight))\n",
    "print(\"Statistics about Edges' Weights\")\n",
    "print(\"Weight mean: \", np.mean(Weight))\n",
    "print(\"Weight median: \", np.median(Weight))\n",
    "print(\"Weight standard deviation: \", np.std(Weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Entries in Current Citation Space:  7866\n"
     ]
    }
   ],
   "source": [
    "len_limit = len(Source)\n",
    "for i in range(len_limit):\n",
    "    # Cutoff citation and reference summatino number to eliminate those less popular papers' citation relationship\n",
    "    cutoff = 6\n",
    "    if Weight[len_limit - 1 - i] <= cutoff:\n",
    "        Source.pop(len_limit - 1 - i)\n",
    "        Target.pop(len_limit - 1 - i)\n",
    "        Weight.pop(len_limit - 1 - i)\n",
    "        Model_group.pop(len_limit - 1 - i)\n",
    "print(\"Number of Entries in Current Citation Space: \", len(Weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7846</th>\n",
       "      <td>[DL] A Survey of FPGA-based Neural Network Inf...</td>\n",
       "      <td>A High Performance FPGA-based Accelerator for ...</td>\n",
       "      <td>30</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7847</th>\n",
       "      <td>[DL] A Survey of FPGA-based Neural Network Inf...</td>\n",
       "      <td>An OpenCL(TM) Deep Learning Accelerator on Arr...</td>\n",
       "      <td>31</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7848</th>\n",
       "      <td>[DL] A Survey of FPGA-based Neural Network Inf...</td>\n",
       "      <td>Automatic Code Generation of Convolutional Neu...</td>\n",
       "      <td>7</td>\n",
       "      <td>LeNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849</th>\n",
       "      <td>[DL] A Survey of FPGA-based Neural Network Inf...</td>\n",
       "      <td>Efficient and Accurate Approximations of Nonli...</td>\n",
       "      <td>55</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7850</th>\n",
       "      <td>[DL] A Survey of FPGA-based Neural Network Inf...</td>\n",
       "      <td>Energy-Efficient CNN Implementation on a Deepl...</td>\n",
       "      <td>30</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7851</th>\n",
       "      <td>[DL] A Survey of FPGA-based Neural Network Inf...</td>\n",
       "      <td>Frequency Domain Acceleration of Convolutional...</td>\n",
       "      <td>56</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>[DL] A Survey of FPGA-based Neural Network Inf...</td>\n",
       "      <td>Frequency Domain Acceleration of Convolutional...</td>\n",
       "      <td>56</td>\n",
       "      <td>GoogleNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7853</th>\n",
       "      <td>cPSO-CNN: An efficient PSO-based algorithm for...</td>\n",
       "      <td>Efficient Optimization of Convolutional Neural...</td>\n",
       "      <td>7</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7854</th>\n",
       "      <td>clCaffe: OpenCL accelerated Caffe for Convolut...</td>\n",
       "      <td>Gradient-based learning applied to document re...</td>\n",
       "      <td>442</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7855</th>\n",
       "      <td>clCaffe: OpenCL accelerated Caffe for Convolut...</td>\n",
       "      <td>ImageNet Classification with Deep Convolutiona...</td>\n",
       "      <td>371</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7856</th>\n",
       "      <td>clCaffe: OpenCL accelerated Caffe for Convolut...</td>\n",
       "      <td>ImageNet Large Scale Visual Recognition Challenge</td>\n",
       "      <td>275</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7857</th>\n",
       "      <td>fpgaConvNet: Mapping Regular and Irregular Con...</td>\n",
       "      <td>A High Performance FPGA-based Accelerator for ...</td>\n",
       "      <td>30</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7858</th>\n",
       "      <td>iFPNA: A Flexible and Efficient Deep Neural Ne...</td>\n",
       "      <td>Eyeriss: An Energy-Efficient Reconfigurable Ac...</td>\n",
       "      <td>47</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7859</th>\n",
       "      <td>iSPLInception: An Inception-ResNet Deep Learni...</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>472</td>\n",
       "      <td>ResNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7860</th>\n",
       "      <td>iSPLInception: An Inception-ResNet Deep Learni...</td>\n",
       "      <td>InceptionTime: Finding AlexNet for time series...</td>\n",
       "      <td>12</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7861</th>\n",
       "      <td>iSPLInception: An Inception-ResNet Deep Learni...</td>\n",
       "      <td>InceptionTime: Finding AlexNet for time series...</td>\n",
       "      <td>12</td>\n",
       "      <td>ResNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7862</th>\n",
       "      <td>pFISTA-SENSE-ResNet for parallel MRI reconstru...</td>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>469</td>\n",
       "      <td>ResNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>vDNN: Virtualized Deep Neural Networks for Sca...</td>\n",
       "      <td>Eyeriss: A Spatial Architecture for Energy-Eff...</td>\n",
       "      <td>24</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>vDNN: Virtualized Deep Neural Networks for Sca...</td>\n",
       "      <td>Gradient-based learning applied to document re...</td>\n",
       "      <td>449</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7865</th>\n",
       "      <td>vDNN: Virtualized Deep Neural Networks for Sca...</td>\n",
       "      <td>Learning both Weights and Connections for Effi...</td>\n",
       "      <td>17</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Source  \\\n",
       "7846  [DL] A Survey of FPGA-based Neural Network Inf...   \n",
       "7847  [DL] A Survey of FPGA-based Neural Network Inf...   \n",
       "7848  [DL] A Survey of FPGA-based Neural Network Inf...   \n",
       "7849  [DL] A Survey of FPGA-based Neural Network Inf...   \n",
       "7850  [DL] A Survey of FPGA-based Neural Network Inf...   \n",
       "7851  [DL] A Survey of FPGA-based Neural Network Inf...   \n",
       "7852  [DL] A Survey of FPGA-based Neural Network Inf...   \n",
       "7853  cPSO-CNN: An efficient PSO-based algorithm for...   \n",
       "7854  clCaffe: OpenCL accelerated Caffe for Convolut...   \n",
       "7855  clCaffe: OpenCL accelerated Caffe for Convolut...   \n",
       "7856  clCaffe: OpenCL accelerated Caffe for Convolut...   \n",
       "7857  fpgaConvNet: Mapping Regular and Irregular Con...   \n",
       "7858  iFPNA: A Flexible and Efficient Deep Neural Ne...   \n",
       "7859  iSPLInception: An Inception-ResNet Deep Learni...   \n",
       "7860  iSPLInception: An Inception-ResNet Deep Learni...   \n",
       "7861  iSPLInception: An Inception-ResNet Deep Learni...   \n",
       "7862  pFISTA-SENSE-ResNet for parallel MRI reconstru...   \n",
       "7863  vDNN: Virtualized Deep Neural Networks for Sca...   \n",
       "7864  vDNN: Virtualized Deep Neural Networks for Sca...   \n",
       "7865  vDNN: Virtualized Deep Neural Networks for Sca...   \n",
       "\n",
       "                                                 Target  Weight      Model  \n",
       "7846  A High Performance FPGA-based Accelerator for ...      30    AlexNet  \n",
       "7847  An OpenCL(TM) Deep Learning Accelerator on Arr...      31    AlexNet  \n",
       "7848  Automatic Code Generation of Convolutional Neu...       7      LeNet  \n",
       "7849  Efficient and Accurate Approximations of Nonli...      55    AlexNet  \n",
       "7850  Energy-Efficient CNN Implementation on a Deepl...      30    AlexNet  \n",
       "7851  Frequency Domain Acceleration of Convolutional...      56    AlexNet  \n",
       "7852  Frequency Domain Acceleration of Convolutional...      56  GoogleNet  \n",
       "7853  Efficient Optimization of Convolutional Neural...       7    AlexNet  \n",
       "7854  Gradient-based learning applied to document re...     442    AlexNet  \n",
       "7855  ImageNet Classification with Deep Convolutiona...     371    AlexNet  \n",
       "7856  ImageNet Large Scale Visual Recognition Challenge     275    AlexNet  \n",
       "7857  A High Performance FPGA-based Accelerator for ...      30    AlexNet  \n",
       "7858  Eyeriss: An Energy-Efficient Reconfigurable Ac...      47    AlexNet  \n",
       "7859       Deep Residual Learning for Image Recognition     472     ResNet  \n",
       "7860  InceptionTime: Finding AlexNet for time series...      12    AlexNet  \n",
       "7861  InceptionTime: Finding AlexNet for time series...      12     ResNet  \n",
       "7862       Deep Residual Learning for Image Recognition     469     ResNet  \n",
       "7863  Eyeriss: A Spatial Architecture for Energy-Eff...      24    AlexNet  \n",
       "7864  Gradient-based learning applied to document re...     449    AlexNet  \n",
       "7865  Learning both Weights and Connections for Effi...      17    AlexNet  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Source': Source, 'Target': Target, 'Weight': Weight, 'Model': Model_group} # Store result as df data type\n",
    "df = pd.DataFrame(data)\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CITE SPACE VISUALIZATION APPROACH - 1\n",
    "# A HOLISTIC VIEW: pyvis, networkx\n",
    "\n",
    "# REFERENCES FOR PYVIS PACKAGE:\n",
    "# https://pyvis.readthedocs.io/en/latest/tutorial.html#node-properties\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.from_pandas_edgelist(df, source = 'Source', target = 'Target', edge_attr = 'Weight')\n",
    "#net = Network(notebook = True)\n",
    "#net.from_nx(G)\n",
    "#net.show(\"example.html\")\n",
    "\n",
    "# all graph options\n",
    "#graphs_viz_options = [nx.draw, nx.draw_networkx, nx.draw_circular, nx.draw_kamada_kawai, nx.draw_random, nx.draw_shell, nx.draw_spring]\n",
    "\n",
    "# plot graph option\n",
    "#selected_graph_option = 0\n",
    "\n",
    "# plot\n",
    "#plt.figure(figsize=(8,6), dpi=100) \n",
    "#graphs_viz_options[selected_graph_option](G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_net = Network(height=\"100%\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", select_menu=True, filter_menu=True)\n",
    "#got_net = Network(height=\"100%\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "got_net.barnes_hut()\n",
    "edge_data = zip(Source, Target, Weight)\n",
    "\n",
    "for e in edge_data:\n",
    "                src = e[0]\n",
    "                dst = e[1]\n",
    "                w = e[2]\n",
    "\n",
    "                got_net.add_node(src, src, title = src)\n",
    "                got_net.add_node(dst, dst, title = dst)\n",
    "                got_net.add_edge(src, dst, value = w)\n",
    "\n",
    "neighbor_map = got_net.get_adj_list()\n",
    "\n",
    "# add neighbor data to node hover data\n",
    "for node in got_net.nodes:\n",
    "                node[\"title\"] += \" -- cited by other \" + str(len(neighbor_map[node[\"id\"]])) + \" papers\"\n",
    "                node_size = (len(neighbor_map[node[\"id\"]])) ** 2 # for easier distinguishibility between node sizes\n",
    "                node[\"value\"] = node_size\n",
    "\n",
    "got_net.show(\"citespace.html\")\n",
    "#got_net.write_html(\"citespace.html\", local=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST HTML for MODEL GROUPS LABELING WITH DIFFERENT COLORS USING PYVIS\n",
    "\n",
    "node_data = {\n",
    "    \"id\": paper,\n",
    "    \"Name\": paper,\n",
    "    \"Model\": paper_model,\n",
    "}\n",
    "edge_data = {\"source\": Source, \"target\": Target}\n",
    "\n",
    "nodes = pd.DataFrame(node_data)\n",
    "edges = pd.DataFrame(edge_data)\n",
    "\n",
    "# getting a group id for each company\n",
    "groups = nodes.groupby(\"Model\")[\"id\"].apply(list).reset_index()\n",
    "groups[\"group\"] = groups.index\n",
    "\n",
    "# finding group id for each node from groups dataframe\n",
    "nodes = nodes.merge(groups, how=\"inner\", on=[\"Model\"])\n",
    "nodes[\"title\"] = nodes[[\"Name\", \"Model\"]].apply(lambda x: f\"Name:{x[0]} , Model:{x[1]}\", axis=1)\n",
    "\n",
    "nodes = nodes.drop(\"id_y\", axis=1).set_index(\"id_x\")\n",
    "\n",
    "# collecting node attributes for network x\n",
    "node_attrs = nodes.to_dict(\"index\")\n",
    "\n",
    "# creating a network x graph from dataframes\n",
    "graph = nx.from_pandas_edgelist(edge_data)\n",
    "nx.set_node_attributes(graph, node_attrs)\n",
    "\n",
    "\n",
    "pyvis_nt = Network(\"1000px\", \"1000px\", heading=\"Graph\")\n",
    "pyvis_nt.from_nx(graph)\n",
    "pyvis_nt.show('test_graph.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CITE SPACE VISUALIZATION APPROACH - 2\n",
    "# PyeCharts\n",
    "# REFERENCE THIS WEB PAGE for General INFO: https://zhuanlan.zhihu.com/p/38305586\n",
    "# AND THIS for General INFO: https://www.heywhale.com/mw/project/5f0d5414597c0f002d5f2e09\n",
    "# AND THIS for General INFO: https://gallery.pyecharts.org/#/Graph/graph_les_miserables\n",
    "# AND THIS for General INFO as Well: https://pyecharts.readthedocs.io/projects/pyecharts-en/zh/latest/en-us/charts_base/#graph\n",
    "# INPUT DATA STRUCTURE: https://gist.github.com/abkunal/98d35b9b235312e90f3e43c9f7b6932b\n",
    "# LabelOpts Choices: https://blog.csdn.net/qq_42374697/article/details/105694022\n",
    "# TitleOpts Choices: https://blog.csdn.net/qq_42374697/article/details/105612266\n",
    "# LegendOpts Choices: https://blog.csdn.net/qq_42374697/article/details/105630669\n",
    "# InitOpts Choices: https://blog.csdn.net/qq_42374697/article/details/105381277\n",
    "# LineStyleOpts Choices: https://blog.csdn.net/qq_42374697/article/details/105694710\n",
    "# THEMETYPE Choices: https://wenku.baidu.com/view/8321f8e1a900b52acfc789eb172ded630a1c9844.html\n",
    "\n",
    "import json\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Graph\n",
    "from pyecharts.globals import ThemeType\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating LINKS\n",
    "OtoV = []\n",
    "for i in range(len(Source)):\n",
    "    OtoV.append({'source': Source[i], 'target': Target[i], 'value': Weight[i]})\n",
    "\n",
    "# Creating NODES\n",
    "Node = []\n",
    "for i in range(len(paper)):\n",
    "    group_position = MODEL.index(paper_model[i])\n",
    "    # for Cleaner label: slicing the paper name and output in two rows\n",
    "    string = paper[i]\n",
    "    slices = string.split(\" \") # Slice strings whenever there is \" \"\n",
    "    former = slices[0 : round(len(slices)/2)]\n",
    "    later = slices[round(len(slices)/2) : len(slices)]\n",
    "    F = \"\"\n",
    "    for f in former:\n",
    "        F = F + \" \" + f\n",
    "    L = \"\"\n",
    "    for l in later:\n",
    "        L = L + \" \" + l\n",
    "    papername_2rows = F + \" \\n\" + L # \"\\n\" seperates two strings will be outputted into seperate rows\n",
    "    \n",
    "    Node.append({\"id\": paper[i], \n",
    "                 \"group\": group_position, \n",
    "                 \"name\": papername_2rows, \n",
    "                 \"symbolSize\": 2 * math.sqrt(count[i]), \n",
    "                 \"category\": paper_model[i]})\n",
    "\n",
    "# Creating CATEGORIES\n",
    "categories = []\n",
    "for i in range(len(MODEL)):\n",
    "    categories.append({\"name\": MODEL[i]})\n",
    "\n",
    "# VISUALIZATION\n",
    "set_color = \"white\"\n",
    "c = (\n",
    "    Graph(init_opts = opts.InitOpts(width = \"900px\",\n",
    "                                    height = \"800px\",\n",
    "                                    page_title = \"Citation Space\",\n",
    "                                    #theme = ThemeType.DARK, # THEME\n",
    "                                    # bg_color = \"#000000\" # Back ground color black\n",
    "                                    ))\n",
    "    .add(\n",
    "        \"\",\n",
    "        nodes = Node,\n",
    "        links = OtoV,\n",
    "        categories = categories,\n",
    "        layout = \"circular\",\n",
    "        #is_rotate_label = True,\n",
    "        is_draggable = True,\n",
    "        repulsion = 100,\n",
    "        linestyle_opts = opts.LineStyleOpts(color = \"source\", \n",
    "                                            curve = 0.3,\n",
    "                                            opacity = 0.7),\n",
    "        label_opts = opts.LabelOpts(position = \"outside\", \n",
    "                                    is_show = False, \n",
    "                                    color = set_color,\n",
    "                                    margin = 50,\n",
    "                                    font_size = 15, \n",
    "                                    font_style = \"normal\",\n",
    "                                    font_weight = \"bold\"),\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        tooltip_opts = opts.TooltipOpts(is_show = True,\n",
    "                                        trigger_on = \"click\",\n",
    "                                        formatter = \"{c}\"),\n",
    "        #title_opts = opts.TitleOpts(title = \"CITATION SPACE\", \n",
    "                                    #subtitle = \"-- Relationships between Papers on \\n   Models Used in Computer Vision\", \n",
    "                                    #pos_left = \"5%\",\n",
    "                                    #item_gap = 20,\n",
    "                                    #title_textstyle_opts = opts.TextStyleOpts(color = set_color, \n",
    "                                                                              #font_size = 40),\n",
    "                                    #subtitle_textstyle_opts = opts.TextStyleOpts(color = set_color, \n",
    "                                                                                 #font_size = 16)),\n",
    "        legend_opts = opts.LegendOpts(orient = \"horizontal\", \n",
    "                                      pos_left = \"0%\", \n",
    "                                      pos_top = \"0%\",\n",
    "                                      padding = 10,\n",
    "                                      item_width = 50,\n",
    "                                      item_height = 25,\n",
    "                                      item_gap = 20,\n",
    "                                      textstyle_opts = opts.TextStyleOpts(color = set_color, \n",
    "                                                                          font_size = 20)),\n",
    "    )\n",
    "    .render(\"CiteSpace_circular.html\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18540ba1c7c6fcf7b094904af32590e47db1238c872b05925d54312909194261"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
